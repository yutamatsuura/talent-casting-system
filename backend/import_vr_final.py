#!/usr/bin/env python3
"""VRãƒ‡ãƒ¼ã‚¿å®Œå…¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå…¨16ãƒ•ã‚¡ã‚¤ãƒ«+æ§‹é€ ä¿®æ­£å¯¾å¿œç‰ˆï¼‰"""

import asyncio
import sys
import pandas as pd
import numpy as np
from pathlib import Path
import re
import chardet

sys.path.insert(0, str(Path(__file__).parent))
from sqlalchemy import text
from app.db.connection import init_db, get_session_maker
from app.models import TalentScore, TalentImage

# 3ã¤ã®VRãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
VR_DIRECTORIES = [
    "/Users/lennon/projects/talent-casting-form/DBæƒ…å ±/ã€VRâ‘ ã€‘Cåˆ—ã®äººæ°—åº¦ã¨ã€Eï½Kåˆ—ã®å„ç¨®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ¡ç”¨ã™ã‚‹æƒ³å®šã§ã™",
    "/Users/lennon/projects/talent-casting-form/DBæƒ…å ±/ã€VRâ‘¡ã€‘Cåˆ—ã®äººæ°—åº¦ã¨ã€Eï½Kåˆ—ã®å„ç¨®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ¡ç”¨ã™ã‚‹æƒ³å®šã§ã™",
    "/Users/lennon/projects/talent-casting-form/DBæƒ…å ±/ã€VRâ‘¢ã€‘Cåˆ—ã®äººæ°—åº¦ã¨ã€Eï½Kåˆ—ã®å„ç¨®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ¡ç”¨ã™ã‚‹æƒ³å®šã§ã™"
]

AsyncSessionLocal = None

async def get_async_session():
    global AsyncSessionLocal
    if AsyncSessionLocal is None:
        await init_db()
        AsyncSessionLocal = get_session_maker()
    return AsyncSessionLocal()

def detect_encoding(file_path):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•æ¤œå‡º"""
    with open(file_path, 'rb') as file:
        raw_data = file.read(10000)  # æœ€åˆã®10KBèª­ã¿å–ã‚Š
        result = chardet.detect(raw_data)
        encoding = result['encoding']

        # æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³
        if encoding in ['SHIFT_JIS', 'CP932', 'Shift_JIS']:
            return 'shift_jis'
        elif encoding in ['UTF-8', 'utf-8']:
            return 'utf-8'
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è©¦ã™é †åº
            return 'shift_jis'

def parse_filename_to_segment(filename):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆIDã‚’å–å¾—"""
    patterns = {
        'å¥³æ€§12': 'F1219',
        'å¥³æ€§20': 'F2034',
        'å¥³æ€§35': 'F3549',
        'å¥³æ€§50': 'F5069',
        'ç”·æ€§12': 'M1219',
        'ç”·æ€§20': 'M2034',
        'ç”·æ€§35': 'M3549',
        'ç”·æ€§50': 'M5069'
    }

    for pattern, code in patterns.items():
        if pattern in filename:
            return code

    print(f"âš ï¸  Unknown segment pattern in filename: {filename}")
    return None

def normalize_name(name):
    """ã‚¿ãƒ¬ãƒ³ãƒˆåã®æ­£è¦åŒ–ï¼ˆã‚¹ãƒšãƒ¼ã‚¹é™¤å»ï¼‰"""
    if pd.isna(name) or name is None:
        return None
    normalized = re.sub(r'[\s\u3000\u00A0\u2000-\u200A\u2028\u2029\u202F\u205F]+', '', str(name))
    return normalized.strip()

async def clear_vr_data():
    """æ—¢å­˜ã®VRãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"""
    print("ğŸ§¹ Clearing existing VR data...")

    async with await get_async_session() as session:
        # talent_imagesãƒ†ãƒ¼ãƒ–ãƒ«å®Œå…¨ã‚¯ãƒªã‚¢ï¼ˆVRã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ‡ãƒ¼ã‚¿ï¼‰
        await session.execute(text("DELETE FROM talent_images"))

        # talent_scoresã®VRé–¢é€£ã‚«ãƒ©ãƒ ã®ã¿NULLã«è¨­å®š
        await session.execute(text("UPDATE talent_scores SET vr_popularity = NULL, base_power_score = NULL"))

        await session.commit()

    print("âœ… VR data cleared")

async def import_vr_complete():
    """å…¨16ãƒ•ã‚¡ã‚¤ãƒ«ã®VRãƒ‡ãƒ¼ã‚¿ã‚’å®Œå…¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    print("=" * 80)
    print("ğŸš€ Starting Complete VR data import (Final Version - Structure Fixed)...")
    print("=" * 80)

    # æ—¢å­˜VRãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢
    await clear_vr_data()

    # ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    async with await get_async_session() as session:
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
        result = await session.execute(text("SELECT id, code, name FROM target_segments"))
        target_segments = {row[1]: row[0] for row in result}
        print(f"ğŸ“Š Target segment mapping: {target_segments}")

        # ã‚¤ãƒ¡ãƒ¼ã‚¸é …ç›®
        result = await session.execute(text("SELECT id, name FROM image_items"))
        image_items = {row[1]: row[0] for row in result}
        print(f"ğŸ“Š Image item mapping: {image_items}")

        # ã‚¿ãƒ¬ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°
        result = await session.execute(text("SELECT id, account_id, name_normalized FROM talents"))
        talent_mapping = {}
        for row in result:
            if row[2]:  # name_normalizedãŒå­˜åœ¨ã™ã‚‹å ´åˆ
                talent_mapping[row[2]] = row[0]
        print(f"ğŸ“Š Talent mapping: {len(talent_mapping)} talents available")

    total_files = 0
    total_imported = 0
    total_errors = 0

    # 3ã¤ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é †æ¬¡å‡¦ç†
    for directory in VR_DIRECTORIES:
        dir_path = Path(directory)
        if not dir_path.exists():
            print(f"âš ï¸  Directory not found: {directory}")
            continue

        csv_files = list(dir_path.glob("*.csv"))
        print(f"\nğŸ“‚ Processing {len(csv_files)} files in {dir_path.name}")

        for csv_file in csv_files:
            print(f"ğŸ” Processing file: {csv_file.name}")

            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆcodeå–å¾—
            segment_code = parse_filename_to_segment(csv_file.name)
            if segment_code is None or segment_code not in target_segments:
                print(f"âš ï¸  Skipping file (unmapped segment): {csv_file.name} -> {segment_code}")
                continue

            segment_id = target_segments[segment_code]
            print(f"âœ… Matched pattern '{segment_code}' to segment_id: {segment_id}")

            try:
                # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è‡ªå‹•æ¤œå‡º
                encoding = detect_encoding(csv_file)
                print(f"ğŸ” Detected encoding: {encoding}")

                # CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆæœ€åˆã®4è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦5è¡Œç›®ã‚’ã‚«ãƒ©ãƒ åã«ï¼‰
                df = pd.read_csv(csv_file, encoding=encoding, skiprows=4)
                print(f"ğŸ“Š CSV shape: {df.shape}")

                # ã‚«ãƒ©ãƒ åç¢ºèª
                print(f"ğŸ·ï¸  Columns: {list(df.columns)}")

                file_imported = 0
                file_errors = 0

                async with await get_async_session() as session:
                    for index, row in df.iterrows():
                        try:
                            # ã‚¿ãƒ¬ãƒ³ãƒˆåã®æ­£è¦åŒ–ã¨ãƒãƒƒãƒ”ãƒ³ã‚°
                            talent_name = normalize_name(row.get('ã‚¿ãƒ¬ãƒ³ãƒˆå'))
                            if not talent_name or talent_name not in talent_mapping:
                                continue

                            talent_id = talent_mapping[talent_name]

                            # VRäººæ°—åº¦ã‚¹ã‚³ã‚¢å‡¦ç†
                            vr_popularity = row.get('äººæ°—åº¦')
                            if pd.notna(vr_popularity):
                                # talent_scoresã«VRäººæ°—åº¦ã‚’æŒ¿å…¥/æ›´æ–°
                                existing_score = await session.execute(
                                    text("SELECT id FROM talent_scores WHERE talent_id = :talent_id AND target_segment_id = :segment_id"),
                                    {"talent_id": talent_id, "segment_id": segment_id}
                                )
                                if existing_score.first():
                                    # æ›´æ–°
                                    await session.execute(
                                        text("UPDATE talent_scores SET vr_popularity = :vr_popularity WHERE talent_id = :talent_id AND target_segment_id = :segment_id"),
                                        {"vr_popularity": float(vr_popularity), "talent_id": talent_id, "segment_id": segment_id}
                                    )
                                else:
                                    # æ–°è¦æŒ¿å…¥
                                    await session.execute(
                                        text("INSERT INTO talent_scores (talent_id, target_segment_id, vr_popularity) VALUES (:talent_id, :segment_id, :vr_popularity)"),
                                        {"talent_id": talent_id, "segment_id": segment_id, "vr_popularity": float(vr_popularity)}
                                    )

                            # ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚³ã‚¢å‡¦ç†ï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã‚’ä½¿ç”¨ï¼‰
                            image_columns = {
                                'ãŠã‚‚ã—ã‚ã„': 'ãŠã‚‚ã—ã‚ã„',
                                'æ¸…æ½”æ„ŸãŒã‚ã‚‹': 'æ¸…æ½”æ„ŸãŒã‚ã‚‹',
                                'å€‹æ€§çš„ãª': 'å€‹æ€§çš„ãª',
                                'ä¿¡é ¼ã§ãã‚‹': 'ä¿¡é ¼ã§ãã‚‹',
                                'ã‚«ãƒƒã‚³ã„ã„': 'ã‚«ãƒƒã‚³ã„ã„',
                                'å¤§äººã®é­…åŠ›ãŒã‚ã‚‹': 'å¤§äººã®é­…åŠ›ãŒã‚ã‚‹'
                            }

                            for image_name, csv_column in image_columns.items():
                                if image_name in image_items and csv_column in df.columns:
                                    image_score = row.get(csv_column)
                                    if pd.notna(image_score):
                                        image_item_id = image_items[image_name]

                                        # talent_imagesã«æŒ¿å…¥
                                        await session.execute(
                                            text("""INSERT INTO talent_images
                                                   (talent_id, target_segment_id, image_item_id, score)
                                                   VALUES (:talent_id, :segment_id, :image_item_id, :score)"""),
                                            {
                                                "talent_id": talent_id,
                                                "segment_id": segment_id,
                                                "image_item_id": image_item_id,
                                                "score": float(image_score)
                                            }
                                        )

                            file_imported += 1

                            # é€²è¡ŒçŠ¶æ³è¡¨ç¤º
                            if file_imported % 100 == 0:
                                print(f"   Processed: {file_imported} records...")
                                await session.commit()

                        except Exception as e:
                            file_errors += 1
                            if file_errors <= 3:  # æœ€åˆã®3ã‚¨ãƒ©ãƒ¼ã®ã¿è¡¨ç¤º
                                print(f"âš ï¸  Row {index} error: {e}")

                    await session.commit()

                print(f"âœ… File completed: {file_imported:,} imported, {file_errors} errors")
                total_imported += file_imported
                total_errors += file_errors
                total_files += 1

            except Exception as e:
                print(f"âŒ File processing error: {e}")
                total_errors += 1

    # æœ€çµ‚çµæœ
    print(f"\nğŸ‰ VR Complete Import Finished!")
    print(f"   ğŸ“ Total files processed: {total_files}")
    print(f"   ğŸ“Š Total imported: {total_imported:,} records")
    print(f"   âŒ Total errors: {total_errors}")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼
    async with await get_async_session() as session:
        # talent_scoresã®VRãƒ‡ãƒ¼ã‚¿ä»¶æ•°
        result = await session.execute(text("SELECT COUNT(*) FROM talent_scores WHERE vr_popularity IS NOT NULL"))
        vr_scores_count = result.scalar()

        # talent_imagesã®ä»¶æ•°
        result = await session.execute(text("SELECT COUNT(*) FROM talent_images"))
        images_count = result.scalar()

        print(f"\nğŸ“Š Database verification:")
        print(f"   VR scores: {vr_scores_count:,} records")
        print(f"   Image scores: {images_count:,} records")

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥çµ±è¨ˆ
        result = await session.execute(text("""
            SELECT ts.code, ts.name, COUNT(*)
            FROM talent_scores sc
            JOIN target_segments ts ON sc.target_segment_id = ts.id
            WHERE sc.vr_popularity IS NOT NULL
            GROUP BY ts.id, ts.code, ts.name
            ORDER BY ts.code
        """))
        segment_stats = result.fetchall()

        print(f"\nğŸ“Š VR data by segment:")
        for row in segment_stats:
            print(f"   {row[0]} ({row[1]}): {row[2]:,} records")

    return total_imported > 0

async def main():
    try:
        success = await import_vr_complete()
        if success:
            print("\nğŸ‰ VR Complete Import SUCCESS!")
            return True
        else:
            print("\nâš ï¸ No VR data imported")
            return False
    except Exception as e:
        print(f"\nâŒ VR Complete Import Error: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)