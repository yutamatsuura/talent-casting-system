#!/usr/bin/env python3
"""VRãƒ‡ãƒ¼ã‚¿ç©¶æ¥µå®Œç¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆ100%ãƒãƒƒãƒãƒ³ã‚°ç‰ˆï¼‰"""

import asyncio
import sys
import pandas as pd
import numpy as np
from pathlib import Path
import re
import chardet
import unicodedata

sys.path.insert(0, str(Path(__file__).parent))
from sqlalchemy import text
from app.db.connection import init_db, get_session_maker
from app.models import TalentScore, TalentImage

# VRãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆçµ±åˆå¾Œï¼‰
VR_DATA_DIRECTORY = "/Users/lennon/projects/talent-casting-form/DBæƒ…å ±/VR_data"

AsyncSessionLocal = None

async def get_async_session():
    global AsyncSessionLocal
    if AsyncSessionLocal is None:
        await init_db()
        AsyncSessionLocal = get_session_maker()
    return AsyncSessionLocal()

def detect_encoding(file_path):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•æ¤œå‡º"""
    with open(file_path, 'rb') as file:
        raw_data = file.read(10000)
        result = chardet.detect(raw_data)
        encoding = result['encoding']

        if encoding in ['SHIFT_JIS', 'CP932', 'Shift_JIS']:
            return 'shift_jis'
        elif encoding in ['UTF-8', 'utf-8']:
            return 'utf-8'
        else:
            return 'shift_jis'

def advanced_normalize_name(name):
    """é«˜åº¦ãªã‚¿ãƒ¬ãƒ³ãƒˆåæ­£è¦åŒ–ï¼ˆVRãƒ‡ãƒ¼ã‚¿å°‚ç”¨ï¼‰"""
    if pd.isna(name) or name is None:
        return None
    name = str(name)
    # Unicodeã®æ­£è¦åŒ–ï¼ˆNFKCã§å…¨è§’â†’åŠè§’ã€æ¿ç‚¹çµ±åˆï¼‰
    name = unicodedata.normalize('NFKC', name)
    # é•·éŸ³ç¬¦ã®çµ±ä¸€ï¼ˆå…¨è§’ãƒ€ãƒƒã‚·ãƒ¥ â†’ é•·éŸ³ç¬¦ï¼‰
    name = re.sub(r'[âˆ’ï¼â”€â”ãƒ¼âˆ’â€]', 'ãƒ¼', name)
    # å…¨è§’è‹±æ•°å­—ã‚’åŠè§’ã«å¤‰æ›
    name = re.sub(r'[ï¼¡-ï¼ºï½-ï½šï¼-ï¼™]', lambda x: chr(ord(x.group()) - 0xFEE0), name)
    # å„ç¨®ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»
    name = re.sub(r'[\s\u3000\u00A0\u2000-\u200A\u2028\u2029\u202F\u205F\uFEFF]+', '', name)
    return name.strip()

def create_name_variants(name):
    """åå‰ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³è‡ªå‹•ç”Ÿæˆ"""
    if not name:
        return []

    variants = []
    # ã‚¹ãƒšãƒ¼ã‚¹ãªã—ç‰ˆ
    variants.append(name)
    # åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ç‰ˆ
    variants.append(name.replace('', ' '))
    # å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ç‰ˆ
    variants.append(name.replace('', 'ã€€'))
    return list(set(variants))

# ç©¶æ¥µæ‰‹å‹•ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå…ƒã®33ä»¶ + æ–°è¦14ä»¶ = 47ä»¶å®Œå…¨ç‰ˆï¼‰
ULTIMATE_MANUAL_MAPPING = {
    # å…ƒã®33ä»¶
    'ãƒãƒ§ã‚³ãƒ¬âˆ’ãƒˆãƒ—ãƒ©ãƒãƒƒãƒˆ': 'ãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆãƒ—ãƒ©ãƒãƒƒãƒˆ',
    'ï¼¤ï¼¡ï¼©ï¼§ï¼¯': 'DAIGO',
    'æ‰€ã€€ã‚¸ãƒ§âˆ’ã‚¸': 'æ‰€ã‚¸ãƒ§ãƒ¼ã‚¸',
    'å‡ºå·ã€€å“²æœ—': 'å‡ºå·å“²æœ—',
    'ãƒã‚«ãƒªã‚ºãƒ ï¼ˆå‡é‡ã€€è‹±çŸ¥ï¼‰': 'ãƒã‚«ãƒªã‚ºãƒ ',
    'ã¿ã‚„ãã‚“ï¼ˆANZENæ¼«æ‰ï¼‰': 'ã¿ã‚„ãã‚“',
    'ã‚ã°ã‚Œã‚‹å›': 'ã‚ã°ã‚Œã‚‹å›',
    'åŠ è—¤ã€€æµ©æ¬¡ï¼ˆæ¥µæ¥½ã¨ã‚“ã¼ï¼‰': 'åŠ è—¤æµ©æ¬¡',
    'å±±ç”°ã€€è£•è²´': 'å±±ç”°è£•è²´',
    'æœ‰å‰ã€€å¼˜è¡Œ': 'æœ‰å‰å¼˜è¡Œ',
    'æ±é‡ã€€å¹¸æ²»': 'æ±é‡å¹¸æ²»',
    'ãµã‹ã‚ã‚Šã‚‡ã†': 'ãµã‹ã‚ã‚Šã‚‡ã†',
    'åšå¤šã€€è¯ä¸¸ãƒ»å¤§å‰': 'åšå¤šè¯ä¸¸ãƒ»å¤§å‰',
    'å‚ä¸Šã€€å¿': 'å‚ä¸Šå¿',
    'åƒé³¥ï¼ˆå¤§æ‚Ÿãƒ»ãƒãƒ–ï¼‰': 'åƒé³¥',
    'ãŠãã‚„ã¯ãï¼ˆå°æœ¨ã€€åšæ˜ãƒ»çŸ¢ä½œã€€å…¼ï¼‰': 'ãŠãã‚„ã¯ã',
    'ã‚¢ãƒ³ã‚¸ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆæ¸¡éƒ¨ã€€å»ºãƒ»å…å¶‹ã€€ä¸€å“‰ï¼‰': 'ã‚¢ãƒ³ã‚¸ãƒ£ãƒƒã‚·ãƒ¥',
    'ãƒŠã‚¤ãƒ³ãƒ†ã‚£ãƒŠã‚¤ãƒ³ï¼ˆå²¡æ‘ã€€éš†å²ãƒ»çŸ¢éƒ¨ã€€æµ©ä¹‹ï¼‰': 'ãƒŠã‚¤ãƒ³ãƒ†ã‚£ãƒŠã‚¤ãƒ³',
    'ãƒ€ã‚¦ãƒ³ã‚¿ã‚¦ãƒ³ï¼ˆæ¾æœ¬ã€€äººå¿—ãƒ»æµœç”°ã€€é›…åŠŸï¼‰': 'ãƒ€ã‚¦ãƒ³ã‚¿ã‚¦ãƒ³',
    'ã¨ã‚“ã­ã‚‹ãšï¼ˆçŸ³æ©‹ã€€è²´æ˜ãƒ»æœ¨æ¢¨ã€€æ†²æ­¦ï¼‰': 'ã¨ã‚“ã­ã‚‹ãš',
    'ãƒ•ãƒƒãƒˆå¾Œè—¤ï¼ˆå¾Œè—¤ã€€è¼åŸºï¼‰': 'ãƒ•ãƒƒãƒˆãƒœãƒ¼ãƒ«ã‚¢ãƒ¯ãƒ¼å¾Œè—¤',
    'ãƒ­ãƒ³ãƒ‰ãƒ³ãƒ–ãƒ¼ãƒ„1å·2å·ï¼ˆç”°æ‘ã€€æ·³ãƒ»ç”°æ‘ã€€äº®ï¼‰': 'ãƒ­ãƒ³ãƒ‰ãƒ³ãƒ–ãƒ¼ãƒ„1å·2å·',
    'ã‚¦ãƒ¼ãƒãƒ³ãƒ©ãƒƒã‚·ãƒ¥ã‚¢ãƒ¯ãƒ¼ï¼ˆæ‘æœ¬ã€€å¤§è¼”ãƒ»ä¸­å·ã€€ãƒ‘ãƒ©ãƒ€ã‚¤ã‚¹ï¼‰': 'ã‚¦ãƒ¼ãƒãƒ³ãƒ©ãƒƒã‚·ãƒ¥ã‚¢ãƒ¯ãƒ¼',
    'ã‚µãƒ³ãƒ‰ã‚¦ã‚£ãƒƒãƒãƒãƒ³ï¼ˆä¼Šé”ã€€ã¿ããŠãƒ»å¯Œæ¾¤ã€€ãŸã‘ã—ï¼‰': 'ã‚µãƒ³ãƒ‰ã‚¦ã‚£ãƒƒãƒãƒãƒ³',
    'ã¯ã‚“ã«ã‚ƒï¼ˆé‡‘ç”°ã€€å“²ãƒ»å·å³¶ã€€ç« è‰¯ï¼‰': 'ã¯ã‚“ã«ã‚ƒ',
    'ã‚¶ãƒ»ãƒ‰ãƒªãƒ•ã‚¿ãƒ¼ã‚ºï¼ˆã„ã‹ã‚Šã‚„ã€€é•·ä»‹ä»–ï¼‰': 'ã‚¶ãƒ»ãƒ‰ãƒªãƒ•ã‚¿ãƒ¼ã‚º',
    'ãƒ‘ãƒ³ã‚µãƒ¼ï¼ˆå‘äº•ã€€æ…§ãƒ»å°¾å½¢ã€€è²´å¼˜ãƒ»è…ã€€è‰¯å¤ªéƒï¼‰': 'ãƒ‘ãƒ³ã‚µãƒ¼',
    'ãƒãƒŠã‚³ï¼ˆå²¡éƒ¨ã€€å¤§ãƒ»ç§‹å±±ã€€å¯›è²´ãƒ»èŠç”°ã€€ç«œå¤§ï¼‰': 'ãƒãƒŠã‚³',
    'éœœé™ã‚Šæ˜æ˜Ÿï¼ˆç²—å“ãƒ»ã›ã„ã‚„ï¼‰': 'éœœé™ã‚Šæ˜æ˜Ÿ',
    'è¦‹å–ã‚Šå›³ï¼ˆç››å±±ã€€æ™‹å¤ªéƒãƒ»ãƒªãƒªãƒ¼ï¼‰': 'è¦‹å–ã‚Šå›³',
    'é‡æ€§çˆ†å¼¾ï¼ˆå·å³¶ã€€é‚¦è£•ãƒ»ãƒ­ãƒƒã‚·ãƒ¼ï¼‰': 'é‡æ€§çˆ†å¼¾',
    'æ±äº¬03ï¼ˆé£¯å¡šã€€æ‚Ÿå¿—ãƒ»è±Šæœ¬ã€€æ˜é•·ãƒ»è§’ç”°ã€€æ™ƒåºƒï¼‰': 'æ±äº¬03',
    'å¸‚å·ã€€æŸ“äº”éƒã€€ï¼ˆè—¤é–“ã€€é½‹ï¼‰': 'å¸‚å·æŸ“äº”éƒ',

    # æ–°è¦14ä»¶è¿½åŠ ï¼ˆæœªç™ºè¦‹å®Œå…¨å¯¾å¿œï¼‰
    'ãƒ“âˆ’ãƒˆãŸã‘ã—ï¼ˆåŒ—é‡ã€€æ­¦ï¼‰': 'ãƒ“ãƒ¼ãƒˆãŸã‘ã—',
    'è‰ãªãã€€å‰›': 'è‰å½…å‰›',
    'å±±å´ã€€è³¢äºº': 'å±±ï¨‘è³¢äºº',
    'ä½ä¹…é–“ã€€å®œè¡Œ': 'ä½ä¹…é–“å®£è¡Œ',
    'ï¼¤ï¼¥ï¼¡ï¼®ã€€ï¼¦ï¼µï¼ªï¼©ï¼¯ï¼«ï¼¡': 'ãƒ‡ã‚£ãƒ¼ãƒ³ãƒ•ã‚¸ã‚ªã‚«',
    'é«˜æ©‹ã€€æµ·äºº': 'é«™æ©‹æµ·äºº',
    'ã•ã¾ãã€œãš': 'ã•ã¾ãï½ãš',
    'ãã£ãâˆ’ï¼': 'ãã£ããƒ¼ï¼',
    'å¸‚å·ã€€åœ˜åéƒç™½çŒ¿ã€€ï¼ˆå €è¶Šã€€å¯¶ä¸–ï¼‰': 'å¸‚å·åœ˜åéƒç™½çŒ¿',
    'ä¸­æ‘ã€€å‹˜ä¹éƒã€€ï¼ˆæ³¢é‡ã€€é›…è¡Œï¼‰': 'ä¸­æ‘å‹˜ä¹éƒ',
    'æ¾æœ¬ã€€å¹¸å››éƒã€€ï¼ˆè—¤é–“ã€€ç…§è–«ï¼‰': 'æ¾æœ¬å¹¸å››éƒ',
    'å¸‚å·ã€€æŸ“äº”éƒã€€ï¼ˆè—¤é–“ã€€é½‹ï¼‰': 'å¸‚å·æŸ“äº”éƒ',
    'é«˜å¶‹ã€€æ”¿å®': 'é«™å¶‹æ”¿å®',
    'é«˜å¶‹ã€€æ”¿ä¼¸': 'é«™å¶‹æ”¿ä¼¸',
}

async def parse_filename_to_segment(filename, target_segments):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆIDã‚’å–å¾—"""
    patterns = {
        'å¥³æ€§12': 'F1219', 'å¥³æ€§20': 'F2034', 'å¥³æ€§35': 'F3549', 'å¥³æ€§50': 'F5069',
        'ç”·æ€§12': 'M1219', 'ç”·æ€§20': 'M2034', 'ç”·æ€§35': 'M3549', 'ç”·æ€§50': 'M5069'
    }

    for pattern, code in patterns.items():
        if pattern in filename and code in target_segments:
            return target_segments[code]

    return None

async def build_ultimate_talent_mapping():
    """ç©¶æ¥µã‚¿ãƒ¬ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰"""
    print("ğŸ”§ ç©¶æ¥µã‚¿ãƒ¬ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰ä¸­...")

    async with await get_async_session() as session:
        result = await session.execute(text("""
            SELECT id, account_id, name, name_normalized
            FROM talents
            WHERE del_flag = 0
            ORDER BY account_id ASC
        """))
        talents = result.fetchall()

        # ãƒ¡ã‚¤ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°
        talent_mapping = {}
        duplicate_mapping = {}
        name_counts = {}

        for talent in talents:
            talent_id, account_id, name, name_normalized = talent

            if not name_normalized:
                continue

            normalized = name_normalized
            if normalized in name_counts:
                name_counts[normalized] += 1
                if normalized not in duplicate_mapping:
                    duplicate_mapping[normalized] = []
                duplicate_mapping[normalized].append({
                    'talent_id': talent_id,
                    'account_id': account_id,
                    'name': name,
                    'name_normalized': name_normalized
                })
            else:
                name_counts[normalized] = 1
                talent_mapping[normalized] = talent_id

            # åå‰ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚è¿½åŠ 
            variants = create_name_variants(normalized)
            for variant in variants:
                if variant != normalized and variant not in talent_mapping:
                    talent_mapping[variant] = talent_id

        print(f"âœ… ç©¶æ¥µãƒãƒƒãƒ”ãƒ³ã‚°: {len(talent_mapping):,}ä»¶")
        print(f"âš ï¸  é‡è¤‡åå‰: {len(duplicate_mapping)}ä»¶")

        if duplicate_mapping:
            print(f"ğŸ“‹ é‡è¤‡åå‰è©³ç´°:")
            for name, duplicates in list(duplicate_mapping.items())[:3]:
                min_account = min(duplicates, key=lambda x: x['account_id'])
                talent_mapping[name] = min_account['talent_id']
                print(f"   ã€Œ{name}ã€: {len(duplicates)}ä»¶ â†’ é¸æŠID:{min_account['talent_id']} account_id:{min_account['account_id']}")

    return talent_mapping, duplicate_mapping

def ultimate_talent_lookup(vr_name, talent_mapping, duplicate_mapping):
    """ç©¶æ¥µã‚¿ãƒ¬ãƒ³ãƒˆåæ¤œç´¢ï¼ˆ5æ®µéšæ¤œç´¢ï¼‰"""
    if not vr_name:
        return None, "empty"

    vr_name = str(vr_name).strip()

    # æ®µéš1: ç›´æ¥ãƒãƒƒãƒãƒ³ã‚°
    normalized_vr = advanced_normalize_name(vr_name)
    if normalized_vr and normalized_vr in talent_mapping:
        return talent_mapping[normalized_vr], "perfect"

    # æ®µéš2: ç©¶æ¥µæ‰‹å‹•ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆ45ä»¶ï¼‰
    if vr_name in ULTIMATE_MANUAL_MAPPING:
        mapped_name = ULTIMATE_MANUAL_MAPPING[vr_name]
        if mapped_name in talent_mapping:
            return talent_mapping[mapped_name], "ultimate"

    # æ®µéš3: ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æ¤œç´¢
    variants = create_name_variants(normalized_vr) if normalized_vr else []
    for variant in variants:
        if variant in talent_mapping:
            return talent_mapping[variant], "variant"

    # æ®µéš4: é‡è¤‡åå‰ã‹ã‚‰æ¤œç´¢
    if normalized_vr and normalized_vr in duplicate_mapping:
        duplicates = duplicate_mapping[normalized_vr]
        min_account = min(duplicates, key=lambda x: x['account_id'])
        return min_account['talent_id'], "duplicate"

    # æ®µéš5: æœªç™ºè¦‹
    return None, "missing"

async def clear_vr_data():
    """æ—¢å­˜ã®VRãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"""
    print("ğŸ§¹ æ—¢å­˜VRãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢ä¸­...")

    async with await get_async_session() as session:
        await session.execute(text("DELETE FROM talent_images"))
        await session.execute(text("UPDATE talent_scores SET vr_popularity = NULL, base_power_score = NULL"))
        await session.commit()

    print("âœ… VRãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢å®Œäº†")

async def import_vr_ultimate():
    """VRãƒ‡ãƒ¼ã‚¿ç©¶æ¥µã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    print("=" * 80)
    print("ğŸŒŸ VRãƒ‡ãƒ¼ã‚¿ç©¶æ¥µã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹ï¼ˆ100%ãƒãƒƒãƒãƒ³ã‚°ç‰ˆï¼‰")
    print("=" * 80)

    # æ—¢å­˜VRãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢
    await clear_vr_data()

    # ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    async with await get_async_session() as session:
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
        result = await session.execute(text("SELECT id, code, name FROM target_segments"))
        target_segments = {row[1]: row[0] for row in result}
        print(f"ğŸ“Š ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: {len(target_segments)}ä»¶")

        # ã‚¤ãƒ¡ãƒ¼ã‚¸é …ç›®
        result = await session.execute(text("SELECT id, name FROM image_items"))
        image_items = {row[1]: row[0] for row in result}
        print(f"ğŸ“Š ã‚¤ãƒ¡ãƒ¼ã‚¸é …ç›®: {len(image_items)}ä»¶")

    # ç©¶æ¥µã‚¿ãƒ¬ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰
    talent_mapping, duplicate_mapping = await build_ultimate_talent_mapping()

    total_files = 0
    total_imported = 0
    perfect_matches = 0
    ultimate_matches = 0
    variant_matches = 0
    duplicate_matches = 0
    still_missing = 0
    total_errors = 0

    # VRãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‡¦ç†ï¼ˆçµ±åˆå¾Œï¼‰
    dir_path = Path(VR_DATA_DIRECTORY)
    if not dir_path.exists():
        print(f"âš ï¸  Directory not found: {VR_DATA_DIRECTORY}")
        return

    csv_files = list(dir_path.glob("*.csv"))
    print(f"\nğŸ“‚ {dir_path.name}: {len(csv_files)}ãƒ•ã‚¡ã‚¤ãƒ«")

    for csv_file in csv_files:
            print(f"ğŸ” {csv_file.name}")

            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°
            segment_id = await parse_filename_to_segment(csv_file.name, target_segments)
            if not segment_id:
                print(f"âš ï¸  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæœªãƒãƒƒãƒ: {csv_file.name}")
                continue

            try:
                encoding = detect_encoding(csv_file)
                df = pd.read_csv(csv_file, encoding=encoding, skiprows=4)
                print(f"ğŸ“Š CSVè¡Œæ•°: {len(df)}ä»¶")

                file_imported = 0
                file_perfect = 0
                file_ultimate = 0
                file_variant = 0
                file_duplicate = 0
                file_missing = 0

                async with await get_async_session() as session:
                    for index, row in df.iterrows():
                        try:
                            vr_talent_name = row.get('ã‚¿ãƒ¬ãƒ³ãƒˆå')
                            talent_id, match_type = ultimate_talent_lookup(vr_talent_name, talent_mapping, duplicate_mapping)

                            if not talent_id:
                                file_missing += 1
                                continue

                            # ãƒãƒƒãƒã‚¿ã‚¤ãƒ—åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
                            if match_type == "perfect":
                                file_perfect += 1
                            elif match_type == "ultimate":
                                file_ultimate += 1
                            elif match_type == "variant":
                                file_variant += 1
                            elif match_type == "duplicate":
                                file_duplicate += 1

                            # VRäººæ°—åº¦å‡¦ç†
                            vr_popularity = row.get('äººæ°—åº¦')
                            if pd.notna(vr_popularity):
                                existing_score = await session.execute(
                                    text("SELECT id FROM talent_scores WHERE talent_id = :talent_id AND target_segment_id = :segment_id"),
                                    {"talent_id": talent_id, "segment_id": segment_id}
                                )
                                if existing_score.first():
                                    await session.execute(
                                        text("UPDATE talent_scores SET vr_popularity = :vr_popularity WHERE talent_id = :talent_id AND target_segment_id = :segment_id"),
                                        {"vr_popularity": float(vr_popularity), "talent_id": talent_id, "segment_id": segment_id}
                                    )
                                else:
                                    await session.execute(
                                        text("INSERT INTO talent_scores (talent_id, target_segment_id, vr_popularity) VALUES (:talent_id, :segment_id, :vr_popularity)"),
                                        {"talent_id": talent_id, "segment_id": segment_id, "vr_popularity": float(vr_popularity)}
                                    )

                            # ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚³ã‚¢å‡¦ç†
                            image_columns = ['ãŠã‚‚ã—ã‚ã„', 'æ¸…æ½”æ„ŸãŒã‚ã‚‹', 'å€‹æ€§çš„ãª', 'ä¿¡é ¼ã§ãã‚‹', 'ã‚«ãƒƒã‚³ã„ã„', 'å¤§äººã®é­…åŠ›ãŒã‚ã‚‹']

                            for image_name in image_columns:
                                if image_name in image_items and image_name in df.columns:
                                    image_score = row.get(image_name)
                                    if pd.notna(image_score):
                                        image_item_id = image_items[image_name]
                                        await session.execute(
                                            text("""INSERT INTO talent_images
                                                   (talent_id, target_segment_id, image_item_id, score)
                                                   VALUES (:talent_id, :segment_id, :image_item_id, :score)"""),
                                            {
                                                "talent_id": talent_id,
                                                "segment_id": segment_id,
                                                "image_item_id": image_item_id,
                                                "score": float(image_score)
                                            }
                                        )

                            file_imported += 1

                            # é€²è¡ŒçŠ¶æ³è¡¨ç¤º
                            if file_imported % 100 == 0:
                                print(f"   å‡¦ç†ä¸­: {file_imported}ä»¶...")
                                await session.commit()

                        except Exception as e:
                            print(f"âš ï¸  è¡Œ{index}ã‚¨ãƒ©ãƒ¼: {e}")

                    await session.commit()

                match_rate = (file_imported / len(df) * 100) if len(df) > 0 else 0
                print(f"âœ… å®Œäº†: {file_imported}/{len(df)}ä»¶ ({match_rate:.1f}%)")
                print(f"   ğŸ¯ å®Œå…¨:{file_perfect} ç©¶æ¥µ:{file_ultimate} å¤‰ç¨®:{file_variant} é‡è¤‡:{file_duplicate} æœªç™ºè¦‹:{file_missing}")

                total_imported += file_imported
                perfect_matches += file_perfect
                ultimate_matches += file_ultimate
                variant_matches += file_variant
                duplicate_matches += file_duplicate
                still_missing += file_missing
                total_files += 1

            except Exception as e:
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
                total_errors += 1

    # æœ€çµ‚çµæœ
    overall_rate = (total_imported / (total_imported + still_missing) * 100) if (total_imported + still_missing) > 0 else 0
    print(f"\nğŸ‰ VRç©¶æ¥µã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†!")
    print(f"   ğŸ“ å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«: {total_files}ä»¶")
    print(f"   ğŸ“Š ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ: {total_imported:,}ä»¶")
    print(f"   ğŸ¯ å®Œå…¨ãƒãƒƒãƒ: {perfect_matches:,}ä»¶")
    print(f"   ğŸŒŸ ç©¶æ¥µãƒãƒƒãƒ: {ultimate_matches:,}ä»¶")
    print(f"   ğŸ”§ å¤‰ç¨®ãƒãƒƒãƒ: {variant_matches:,}ä»¶")
    print(f"   ğŸ” é‡è¤‡ãƒãƒƒãƒ: {duplicate_matches:,}ä»¶")
    print(f"   âŒ æœªç™ºè¦‹: {still_missing:,}ä»¶")
    print(f"   ğŸ“ˆ ç©¶æ¥µãƒãƒƒãƒç‡: {overall_rate:.2f}%")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼
    async with await get_async_session() as session:
        result = await session.execute(text("SELECT COUNT(*) FROM talent_scores WHERE vr_popularity IS NOT NULL"))
        vr_scores_count = result.scalar()

        result = await session.execute(text("SELECT COUNT(*) FROM talent_images"))
        images_count = result.scalar()

        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼:")
        print(f"   VRã‚¹ã‚³ã‚¢: {vr_scores_count:,}ä»¶")
        print(f"   ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚³ã‚¢: {images_count:,}ä»¶")

    return total_imported > 0

async def main():
    try:
        success = await import_vr_ultimate()
        if success:
            print("\nğŸ‰ VRç©¶æ¥µã‚¤ãƒ³ãƒãƒ¼ãƒˆ SUCCESS!")
            return True
        else:
            print("\nâš ï¸ VRãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆãªã—")
            return False
    except Exception as e:
        print(f"\nâŒ VRç©¶æ¥µã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)