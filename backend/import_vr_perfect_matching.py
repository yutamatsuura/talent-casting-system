#!/usr/bin/env python3
"""VRãƒ‡ãƒ¼ã‚¿å®Œå…¨ãƒãƒƒãƒãƒ³ã‚°ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆ100%ãƒãƒƒãƒãƒ³ã‚°å¯¾å¿œç‰ˆï¼‰"""

import asyncio
import sys
import pandas as pd
import numpy as np
from pathlib import Path
import re
import chardet
import unicodedata

sys.path.insert(0, str(Path(__file__).parent))
from sqlalchemy import text
from app.db.connection import init_db, get_session_maker
from app.models import TalentScore, TalentImage

# 3ã¤ã®VRãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
VR_DIRECTORIES = [
    "/Users/lennon/projects/talent-casting-form/DBæƒ…å ±/ã€VRâ‘ ã€‘Cåˆ—ã®äººæ°—åº¦ã¨ã€Eï½Kåˆ—ã®å„ç¨®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ¡ç”¨ã™ã‚‹æƒ³å®šã§ã™",
    "/Users/lennon/projects/talent-casting-form/DBæƒ…å ±/ã€VRâ‘¡ã€‘Cåˆ—ã®äººæ°—åº¦ã¨ã€Eï½Kåˆ—ã®å„ç¨®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ¡ç”¨ã™ã‚‹æƒ³å®šã§ã™",
    "/Users/lennon/projects/talent-casting-form/DBæƒ…å ±/ã€VRâ‘¢ã€‘Cåˆ—ã®äººæ°—åº¦ã¨ã€Eï½Kåˆ—ã®å„ç¨®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ¡ç”¨ã™ã‚‹æƒ³å®šã§ã™"
]

AsyncSessionLocal = None

async def get_async_session():
    global AsyncSessionLocal
    if AsyncSessionLocal is None:
        await init_db()
        AsyncSessionLocal = get_session_maker()
    return AsyncSessionLocal()

def detect_encoding(file_path):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è‡ªå‹•æ¤œå‡º"""
    with open(file_path, 'rb') as file:
        raw_data = file.read(10000)
        result = chardet.detect(raw_data)
        encoding = result['encoding']

        if encoding in ['SHIFT_JIS', 'CP932', 'Shift_JIS']:
            return 'shift_jis'
        elif encoding in ['UTF-8', 'utf-8']:
            return 'utf-8'
        else:
            return 'shift_jis'

def advanced_normalize_name(name):
    """é«˜åº¦ãªã‚¿ãƒ¬ãƒ³ãƒˆåæ­£è¦åŒ–ï¼ˆVRãƒ‡ãƒ¼ã‚¿å°‚ç”¨ï¼‰"""
    if pd.isna(name) or name is None:
        return None

    # æ–‡å­—åˆ—å¤‰æ›
    name = str(name)

    # Unicodeã®æ­£è¦åŒ–ï¼ˆNFKCã§å…¨è§’â†’åŠè§’ã€æ¿ç‚¹çµ±åˆï¼‰
    name = unicodedata.normalize('NFKC', name)

    # é•·éŸ³ç¬¦ã®çµ±ä¸€ï¼ˆå…¨è§’ãƒ€ãƒƒã‚·ãƒ¥ â†’ é•·éŸ³ç¬¦ï¼‰
    name = re.sub(r'[âˆ’ï¼â”€â”ãƒ¼âˆ’â€]', 'ãƒ¼', name)

    # å…¨è§’è‹±æ•°å­—ã‚’åŠè§’ã«å¤‰æ›
    name = re.sub(r'[ï¼¡-ï¼ºï½-ï½šï¼-ï¼™]', lambda x: chr(ord(x.group()) - 0xFEE0), name)

    # å„ç¨®ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»ï¼ˆå…¨è§’ã€åŠè§’ã€ã‚¼ãƒ­å¹…ç­‰ï¼‰
    name = re.sub(r'[\s\u3000\u00A0\u2000-\u200A\u2028\u2029\u202F\u205F\uFEFF]+', '', name)

    # æ‹¬å¼§å†…ã®ã‚¹ãƒšãƒ¼ã‚¹é™¤å»
    name = re.sub(r'ï¼ˆ\s+', 'ï¼ˆ', name)
    name = re.sub(r'\s+ï¼‰', 'ï¼‰', name)

    return name.strip()

def create_name_variants(name):
    """åå‰ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆï¼ˆãƒãƒƒãƒãƒ³ã‚°ç‡å‘ä¸Šç”¨ï¼‰"""
    if not name:
        return []

    variants = [name]

    # é•·éŸ³ç¬¦ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
    variants.append(re.sub(r'ãƒ¼', 'âˆ’', name))  # é•·éŸ³ç¬¦ â†’ ãƒ€ãƒƒã‚·ãƒ¥
    variants.append(re.sub(r'ãƒ¼', 'ï¼', name))  # é•·éŸ³ç¬¦ â†’ å…¨è§’ãƒ€ãƒƒã‚·ãƒ¥

    # å…¨è§’ãƒ»åŠè§’ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³
    variants.append(re.sub(r'[A-Za-z0-9]', lambda x: chr(ord(x.group()) + 0xFEE0), name))  # åŠè§’â†’å…¨è§’

    # ã‚¹ãƒšãƒ¼ã‚¹ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆç‰¹å®šã®æ–‡å­—é–“ã«è¿½åŠ ï¼‰
    if 'ã€€' not in name and len(name) >= 4:
        # å§“åã£ã½ã„åˆ†é›¢ç‚¹ã‚’è¦‹ã¤ã‘ã¦ã‚¹ãƒšãƒ¼ã‚¹ã‚’æŒ¿å…¥
        for i in range(1, len(name)):
            if i < len(name) - 1:
                variant_with_space = name[:i] + 'ã€€' + name[i:]
                variants.append(variant_with_space)

    return list(set(variants))  # é‡è¤‡é™¤å»

async def build_perfect_talent_mapping():
    """å®Œç’§ãªtalent mappingæ§‹ç¯‰ï¼ˆé‡è¤‡å¯¾å¿œãƒ»ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰"""
    print("ğŸ”§ å®Œç’§ãªã‚¿ãƒ¬ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰ä¸­...")

    async with await get_async_session() as session:
        # å…¨talenãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰
        result = await session.execute(text("""
            SELECT id, account_id, name, name_normalized
            FROM talents
            WHERE del_flag = 0
            ORDER BY account_id ASC
        """))
        talents = result.fetchall()

        # ãƒ¡ã‚¤ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°
        talent_mapping = {}

        # é‡è¤‡åå‰ã®è©³ç´°ç®¡ç†
        duplicate_mapping = {}
        name_counts = {}

        for talent in talents:
            talent_id, account_id, name, name_normalized = talent

            if not name_normalized:
                continue

            # é«˜åº¦æ­£è¦åŒ–
            normalized = advanced_normalize_name(name_normalized)
            if not normalized:
                continue

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if normalized in name_counts:
                name_counts[normalized] += 1
                if normalized not in duplicate_mapping:
                    duplicate_mapping[normalized] = []
                duplicate_mapping[normalized].append({
                    'talent_id': talent_id,
                    'account_id': account_id,
                    'name': name,
                    'name_normalized': name_normalized
                })
            else:
                name_counts[normalized] = 1
                talent_mapping[normalized] = talent_id

            # åå‰ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚è¿½åŠ 
            variants = create_name_variants(normalized)
            for variant in variants:
                if variant != normalized and variant not in talent_mapping:
                    talent_mapping[variant] = talent_id

        print(f"âœ… ãƒ¡ã‚¤ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°: {len(talent_mapping):,}ä»¶")
        print(f"âš ï¸  é‡è¤‡åå‰: {len(duplicate_mapping)}ä»¶")

        if duplicate_mapping:
            print("ğŸ“‹ é‡è¤‡åå‰è©³ç´°:")
            for name, duplicates in duplicate_mapping.items():
                print(f"   ã€Œ{name}ã€: {len(duplicates)}ä»¶")
                for dup in duplicates:
                    print(f"     ID:{dup['talent_id']} account_id:{dup['account_id']} name:ã€Œ{dup['name']}ã€")

        return talent_mapping, duplicate_mapping

# æ‰‹å‹•ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆVRã®åå‰è¡¨è¨˜ â†’ æ­£è¦åŒ–åå‰ï¼‰
MANUAL_MAPPING = {
    'ãƒãƒ§ã‚³ãƒ¬âˆ’ãƒˆãƒ—ãƒ©ãƒãƒƒãƒˆ': 'ãƒãƒ§ã‚³ãƒ¬ãƒ¼ãƒˆãƒ—ãƒ©ãƒãƒƒãƒˆ',
    'ï¼¤ï¼¡ï¼©ï¼§ï¼¯': 'DAIGO',
    'æ‰€ã€€ã‚¸ãƒ§âˆ’ã‚¸': 'æ‰€ã‚¸ãƒ§ãƒ¼ã‚¸',
    'ã‚«ã‚ºãƒ¬âˆ’ã‚¶âˆ’': 'ã‚«ã‚ºãƒ¬ãƒ¼ã‚¶ãƒ¼',
    'ã‚±ãƒ³ãƒ‰âˆ’ã‚³ãƒãƒ¤ã‚·': 'ã‚±ãƒ³ãƒ‰ãƒ¼ã‚³ãƒãƒ¤ã‚·',
    'ãƒ“âˆ’ãƒˆãŸã‘ã—ï¼ˆåŒ—é‡ã€€æ­¦ï¼‰': 'ãƒ“ãƒ¼ãƒˆãŸã‘ã—ï¼ˆåŒ—é‡æ­¦ï¼‰',
    'ã‚¿ã‚¤ãƒ ãƒã‚·âˆ’ãƒ³ï¼“å·': 'ã‚¿ã‚¤ãƒ ãƒã‚·ãƒ¼ãƒ³3å·',
    'ã•ã¾ãã€œãš': 'ã•ã¾ãï½ãš',
    'ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒ¨ãƒâˆ’ã‚º': 'ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒ¨ãƒãƒ¼ã‚º',
    'ãã£ãâˆ’ï¼': 'ãã£ããƒ¼ï¼',
    'ï¼©ï¼«ï¼«ï¼¯': 'IKKO',
    'è‰ãªãã€€å‰›': 'è‰ãªãå‰›',
    'ã‚ªãƒ€ã‚®ãƒªã€€ã‚¸ãƒ§âˆ’': 'ã‚ªãƒ€ã‚®ãƒªã‚¸ãƒ§ãƒ¼',
    'ï¼¨ï¼©ï¼«ï¼¡ï¼«ï¼©ï¼®': 'HIKAKIN',
    'ãƒ¦âˆ’ã‚¹ã‚±ãƒ»ã‚µãƒ³ã‚¿ãƒãƒªã‚¢': 'ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ»ã‚µãƒ³ã‚¿ãƒãƒªã‚¢',
    'å±±å´ã€€è³¢äºº': 'å±±å´è³¢äºº',
    'ãƒ‹ãƒ¥âˆ’ãƒ¨âˆ’ã‚¯': 'ãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯',
    'ï¼¥ï¼¸ï¼©ï¼´': 'EXIT',
    'ãƒªãƒªâˆ’ãƒ»ãƒ•ãƒ©ãƒ³ã‚­âˆ’': 'ãƒªãƒªãƒ¼ãƒ»ãƒ•ãƒ©ãƒ³ã‚­ãƒ¼',
    'ä½ä¹…é–“ã€€å®œè¡Œ': 'ä½ä¹…é–“å®œè¡Œ',
    'é–¢å£ã€€ãƒ¡ãƒ³ãƒ‡ã‚£âˆ’': 'é–¢å£ãƒ¡ãƒ³ãƒ‡ã‚£ãƒ¼',
    'ï¼¤ï¼¥ï¼¡ï¼®ã€€ï¼¦ï¼µï¼ªï¼©ï¼¯ï¼«ï¼¡': 'DEAN FUJIOKA',
    'ã¯ã˜ã‚ã—ã‚ƒã¡ã‚‡âˆ’': 'ã¯ã˜ã‚ã—ã‚ƒã¡ã‚‡ãƒ¼',
    'ãƒã‚­ã‚¿ã‚¹ãƒâˆ’ãƒ„': 'ãƒã‚­ã‚¿ã‚¹ãƒãƒ¼ãƒ„',
    'ãƒ©ã‚¦âˆ’ãƒ«': 'ãƒ©ã‚¦ãƒ¼ãƒ«',
    'ã‚¸ã‚§ã‚·âˆ’': 'ã‚¸ã‚§ã‚·ãƒ¼',
    'é«˜æ©‹ã€€æµ·äºº': 'é«˜æ©‹æµ·äºº',
    'å¸‚å·ã€€åœ˜åéƒç™½çŒ¿ã€€ï¼ˆå €è¶Šã€€å¯¶ä¸–ï¼‰': 'å¸‚å·åœ˜åéƒç™½çŒ¿ï¼ˆå €è¶Šå¯¶ä¸–ï¼‰',
    'é«˜å¶‹ã€€æ”¿ä¼¸': 'é«˜å¶‹æ”¿ä¼¸',
    'é«˜å¶‹ã€€æ”¿å®': 'é«˜å¶‹æ”¿å®',
    'ä¸­æ‘ã€€å‹˜ä¹éƒã€€ï¼ˆæ³¢é‡ã€€é›…è¡Œï¼‰': 'ä¸­æ‘å‹˜ä¹éƒï¼ˆæ³¢é‡é›…è¡Œï¼‰',
    'æ¾æœ¬ã€€å¹¸å››éƒã€€ï¼ˆè—¤é–“ã€€ç…§è–«ï¼‰': 'æ¾æœ¬å¹¸å››éƒï¼ˆè—¤é–“ç…§è–«ï¼‰',
    'å¸‚å·ã€€æŸ“äº”éƒã€€ï¼ˆè—¤é–“ã€€é½‹ï¼‰': 'å¸‚å·æŸ“äº”éƒï¼ˆè—¤é–“é½‹ï¼‰',
}

def enhanced_talent_lookup(vr_name, talent_mapping, duplicate_mapping):
    """å¼·åŒ–ã•ã‚ŒãŸã‚¿ãƒ¬ãƒ³ãƒˆåæ¤œç´¢"""
    if not vr_name:
        return None

    # Step 1: é«˜åº¦æ­£è¦åŒ–
    normalized_vr = advanced_normalize_name(vr_name)
    if not normalized_vr:
        return None

    # Step 2: ç›´æ¥ãƒãƒƒãƒãƒ³ã‚°
    if normalized_vr in talent_mapping:
        return talent_mapping[normalized_vr]

    # Step 3: æ‰‹å‹•ãƒãƒƒãƒ”ãƒ³ã‚°é©ç”¨
    if vr_name in MANUAL_MAPPING:
        corrected_name = MANUAL_MAPPING[vr_name]
        corrected_normalized = advanced_normalize_name(corrected_name)
        if corrected_normalized in talent_mapping:
            return talent_mapping[corrected_normalized]

    # Step 4: ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æ¤œç´¢
    variants = create_name_variants(normalized_vr)
    for variant in variants:
        if variant in talent_mapping:
            return talent_mapping[variant]

    # Step 5: é‡è¤‡åå‰ã§ã®æ¤œç´¢ï¼ˆæœ€åˆã®IDã‚’è¿”ã™ï¼‰
    if normalized_vr in duplicate_mapping:
        return duplicate_mapping[normalized_vr][0]['talent_id']

    return None

async def parse_filename_to_segment(filename, target_segments):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆIDã‚’å–å¾—"""
    patterns = {
        'å¥³æ€§12': 'F1219',
        'å¥³æ€§20': 'F2034',
        'å¥³æ€§35': 'F3549',
        'å¥³æ€§50': 'F5069',
        'ç”·æ€§12': 'M1219',
        'ç”·æ€§20': 'M2034',
        'ç”·æ€§35': 'M3549',
        'ç”·æ€§50': 'M5069'
    }

    for pattern, code in patterns.items():
        if pattern in filename:
            return target_segments.get(code)

    return None

async def clear_vr_data():
    """æ—¢å­˜ã®VRãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢"""
    print("ğŸ§¹ æ—¢å­˜VRãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢ä¸­...")

    async with await get_async_session() as session:
        await session.execute(text("DELETE FROM talent_images"))
        await session.execute(text("UPDATE talent_scores SET vr_popularity = NULL, base_power_score = NULL"))
        await session.commit()

    print("âœ… VRãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢å®Œäº†")

async def import_vr_perfect():
    """VRãƒ‡ãƒ¼ã‚¿å®Œç’§ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆ100%ãƒãƒƒãƒãƒ³ã‚°ç‰ˆï¼‰"""
    print("=" * 80)
    print("ğŸŒŸ VRãƒ‡ãƒ¼ã‚¿å®Œç’§ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹ï¼ˆ100%ãƒãƒƒãƒãƒ³ã‚°ç‰ˆï¼‰")
    print("=" * 80)

    await clear_vr_data()

    # ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    async with await get_async_session() as session:
        result = await session.execute(text("SELECT id, code, name FROM target_segments"))
        target_segments = {row[1]: row[0] for row in result}

        result = await session.execute(text("SELECT id, name FROM image_items"))
        image_items = {row[1]: row[0] for row in result}

        print(f"ğŸ“Š ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: {len(target_segments)}ä»¶")
        print(f"ğŸ“Š ã‚¤ãƒ¡ãƒ¼ã‚¸é …ç›®: {len(image_items)}ä»¶")

    # å®Œç’§ãªã‚¿ãƒ¬ãƒ³ãƒˆãƒãƒƒãƒ”ãƒ³ã‚°æ§‹ç¯‰
    talent_mapping, duplicate_mapping = await build_perfect_talent_mapping()

    total_files = 0
    total_imported = 0
    total_errors = 0
    perfect_matches = 0
    enhanced_matches = 0
    still_missing = 0

    # 3ã¤ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’é †æ¬¡å‡¦ç†
    for directory in VR_DIRECTORIES:
        dir_path = Path(directory)
        if not dir_path.exists():
            continue

        csv_files = list(dir_path.glob("*.csv"))
        print(f"\nğŸ“‚ {dir_path.name}: {len(csv_files)}ãƒ•ã‚¡ã‚¤ãƒ«")

        for csv_file in csv_files:
            print(f"ğŸ” {csv_file.name}")

            segment_id = await parse_filename_to_segment(csv_file.name, target_segments)
            if not segment_id:
                print(f"âš ï¸  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæœªãƒãƒƒãƒ: {csv_file.name}")
                continue

            try:
                encoding = detect_encoding(csv_file)
                df = pd.read_csv(csv_file, encoding=encoding, skiprows=4)

                file_imported = 0
                file_perfect = 0
                file_enhanced = 0
                file_missing = 0

                async with await get_async_session() as session:
                    for index, row in df.iterrows():
                        try:
                            vr_talent_name = row.get('ã‚¿ãƒ¬ãƒ³ãƒˆå')
                            talent_id = enhanced_talent_lookup(vr_talent_name, talent_mapping, duplicate_mapping)

                            if not talent_id:
                                file_missing += 1
                                continue

                            # ãƒãƒƒãƒãƒ³ã‚°ç¨®åˆ¥åˆ¤å®š
                            normalized_vr = advanced_normalize_name(vr_talent_name)
                            if normalized_vr in talent_mapping:
                                file_perfect += 1
                            else:
                                file_enhanced += 1

                            # VRäººæ°—åº¦å‡¦ç†
                            vr_popularity = row.get('äººæ°—åº¦')
                            if pd.notna(vr_popularity):
                                existing_score = await session.execute(
                                    text("SELECT id FROM talent_scores WHERE talent_id = :talent_id AND target_segment_id = :segment_id"),
                                    {"talent_id": talent_id, "segment_id": segment_id}
                                )
                                if existing_score.first():
                                    await session.execute(
                                        text("UPDATE talent_scores SET vr_popularity = :vr_popularity WHERE talent_id = :talent_id AND target_segment_id = :segment_id"),
                                        {"vr_popularity": float(vr_popularity), "talent_id": talent_id, "segment_id": segment_id}
                                    )
                                else:
                                    await session.execute(
                                        text("INSERT INTO talent_scores (talent_id, target_segment_id, vr_popularity) VALUES (:talent_id, :segment_id, :vr_popularity)"),
                                        {"talent_id": talent_id, "segment_id": segment_id, "vr_popularity": float(vr_popularity)}
                                    )

                            # ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚³ã‚¢å‡¦ç†
                            image_columns = {
                                'ãŠã‚‚ã—ã‚ã„': 'ãŠã‚‚ã—ã‚ã„',
                                'æ¸…æ½”æ„ŸãŒã‚ã‚‹': 'æ¸…æ½”æ„ŸãŒã‚ã‚‹',
                                'å€‹æ€§çš„ãª': 'å€‹æ€§çš„',
                                'ä¿¡é ¼ã§ãã‚‹': 'ä¿¡é ¼ã§ãã‚‹',
                                'ã‚«ãƒƒã‚³ã„ã„': 'ã‚«ãƒƒã‚³ã„ã„',
                                'å¤§äººã®é­…åŠ›ãŒã‚ã‚‹': 'å¤§äººã£ã½ã„'  # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã‚‹
                            }

                            for vr_col, db_image in image_columns.items():
                                if db_image in image_items and vr_col in df.columns:
                                    image_score = row.get(vr_col)
                                    if pd.notna(image_score):
                                        image_item_id = image_items[db_image]
                                        await session.execute(
                                            text("""INSERT INTO talent_images
                                                   (talent_id, target_segment_id, image_item_id, score)
                                                   VALUES (:talent_id, :segment_id, :image_item_id, :score)"""),
                                            {
                                                "talent_id": talent_id,
                                                "segment_id": segment_id,
                                                "image_item_id": image_item_id,
                                                "score": float(image_score)
                                            }
                                        )

                            file_imported += 1

                            if file_imported % 100 == 0:
                                print(f"   é€²è¡Œ: {file_imported}ä»¶...")
                                await session.commit()

                        except Exception as e:
                            total_errors += 1
                            if total_errors <= 5:
                                print(f"âš ï¸  Row {index} error: {e}")

                    await session.commit()

                match_rate = (file_imported / len(df) * 100) if len(df) > 0 else 0
                print(f"âœ… å®Œäº†: {file_imported}/{len(df)}ä»¶ ({match_rate:.1f}%) | å®Œå…¨:{file_perfect} æ‹¡å¼µ:{file_enhanced} æœªç™ºè¦‹:{file_missing}")

                total_imported += file_imported
                perfect_matches += file_perfect
                enhanced_matches += file_enhanced
                still_missing += file_missing
                total_files += 1

            except Exception as e:
                print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
                total_errors += 1

    # æœ€çµ‚çµæœ
    overall_rate = (total_imported / (total_imported + still_missing) * 100) if (total_imported + still_missing) > 0 else 0
    print(f"\nğŸ‰ VRå®Œç’§ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†!")
    print(f"   ğŸ“ å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«: {total_files}ä»¶")
    print(f"   ğŸ“Š ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ: {total_imported:,}ä»¶")
    print(f"   ğŸ¯ å®Œå…¨ãƒãƒƒãƒ: {perfect_matches:,}ä»¶")
    print(f"   ğŸ”§ æ‹¡å¼µãƒãƒƒãƒ: {enhanced_matches:,}ä»¶")
    print(f"   âŒ æœªç™ºè¦‹: {still_missing:,}ä»¶")
    print(f"   ğŸ“ˆ å…¨ä½“ãƒãƒƒãƒç‡: {overall_rate:.2f}%")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼
    async with await get_async_session() as session:
        result = await session.execute(text("SELECT COUNT(*) FROM talent_scores WHERE vr_popularity IS NOT NULL"))
        vr_scores_count = result.scalar()

        result = await session.execute(text("SELECT COUNT(*) FROM talent_images"))
        images_count = result.scalar()

        print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œè¨¼:")
        print(f"   VRã‚¹ã‚³ã‚¢: {vr_scores_count:,}ä»¶")
        print(f"   ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚³ã‚¢: {images_count:,}ä»¶")

    return total_imported > 0

async def main():
    try:
        success = await import_vr_perfect()
        if success:
            print("\nğŸ‰ VRå®Œç’§ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ!")
            return True
        else:
            print("\nâš ï¸  VRã‚¤ãƒ³ãƒãƒ¼ãƒˆã§å•é¡Œç™ºç”Ÿ")
            return False
    except Exception as e:
        print(f"\nâŒ VRå®Œç’§ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)