#!/usr/bin/env python3
"""
ã‚¯ã‚¤ãƒƒã‚¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯
æ—¥å¸¸çš„ãªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ä½œæ¥­ç”¨ã®è»½é‡ãƒ†ã‚¹ãƒˆ
"""

import time
import json
import statistics
import requests
from datetime import datetime
from typing import Dict, Any, List

class QuickPerformanceCheck:
    """è»½é‡ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¯ãƒ©ã‚¹"""

    def __init__(self, api_base_url: str = "http://localhost:8432"):
        self.api_base_url = api_base_url

    def test_single_scenario(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """å˜ä¸€ã‚·ãƒŠãƒªã‚ªã®é«˜é€Ÿãƒ†ã‚¹ãƒˆ"""
        print(f"âš¡ ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: {payload['company_name']}")

        response_times = []
        result_counts = []

        # 3å›å®Ÿè¡Œï¼ˆè»½é‡ï¼‰
        for i in range(3):
            start_time = time.time()

            try:
                response = requests.post(
                    f"{self.api_base_url}/api/matching",
                    json=payload,
                    timeout=15
                )
                response.raise_for_status()
                result_data = response.json()

                end_time = time.time()
                response_time = end_time - start_time

                response_times.append(response_time)
                result_counts.append(len(result_data.get('results', [])))

                print(f"  è©¦è¡Œ {i+1}: {response_time:.3f}ç§’, {result_counts[-1]}ä»¶")

            except Exception as e:
                print(f"  è©¦è¡Œ {i+1}: ã‚¨ãƒ©ãƒ¼ - {str(e)}")
                continue

            time.sleep(0.5)  # çŸ­ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«

        if not response_times:
            return {"error": "å…¨ã¦ã®è©¦è¡ŒãŒå¤±æ•—"}

        # çµæœé›†è¨ˆ
        avg_time = statistics.mean(response_times)
        max_time = max(response_times)
        avg_results = statistics.mean(result_counts)

        # è©•ä¾¡
        performance_grade = self._grade_performance(avg_time, max_time)

        return {
            "avg_response_time": avg_time,
            "max_response_time": max_time,
            "avg_result_count": avg_results,
            "performance_grade": performance_grade,
            "samples": len(response_times)
        }

    def _grade_performance(self, avg_time: float, max_time: float) -> Dict[str, str]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡"""
        if avg_time <= 1.0 and max_time <= 2.0:
            return {"grade": "A", "status": "å„ªç§€", "emoji": "ğŸš€"}
        elif avg_time <= 2.0 and max_time <= 3.0:
            return {"grade": "B", "status": "è‰¯å¥½", "emoji": "âœ…"}
        elif avg_time <= 3.0 and max_time <= 5.0:
            return {"grade": "C", "status": "æ™®é€š", "emoji": "âš ï¸"}
        else:
            return {"grade": "D", "status": "è¦æ”¹å–„", "emoji": "âŒ"}

    def run_quick_benchmark(self) -> Dict[str, Any]:
        """ã‚¯ã‚¤ãƒƒã‚¯ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        print("ğŸ¯ ã‚¯ã‚¤ãƒƒã‚¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯é–‹å§‹")
        print("-" * 50)

        # ä»£è¡¨çš„ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ï¼ˆè»½é‡ç‰ˆï¼‰
        test_cases = [
            {
                "name": "äººæ°—ã‚±ãƒ¼ã‚¹",
                "payload": {
                    "company_name": "æ ªå¼ä¼šç¤¾ãƒ†ã‚¹ãƒˆãƒ“ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ¼",
                    "industry": "åŒ–ç²§å“ãƒ»ãƒ˜ã‚¢ã‚±ã‚¢ãƒ»ã‚ªãƒ¼ãƒ©ãƒ«ã‚±ã‚¢",
                    "target_segments": "å¥³æ€§20-34æ­³",
                    "purpose": "ãƒ–ãƒ©ãƒ³ãƒ‰ã®èªçŸ¥åº¦å‘ä¸Šã®ãŸã‚",
                    "budget": "3,000ä¸‡å††ã€œ1å„„å††æœªæº€",
                    "email": "test@beauty-test.com"
                }
            },
            {
                "name": "ä¸€èˆ¬ã‚±ãƒ¼ã‚¹",
                "payload": {
                    "company_name": "æ ªå¼ä¼šç¤¾ãƒ†ã‚¹ãƒˆãƒ•ãƒ¼ãƒ‰",
                    "industry": "é£Ÿå“",
                    "target_segments": "å¥³æ€§35-49æ­³",
                    "purpose": "æ–°å•†å“ã®ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚",
                    "budget": "1,000ä¸‡å††ã€œ3,000ä¸‡å††æœªæº€",
                    "email": "test@food-test.com"
                }
            }
        ]

        results = {}
        overall_times = []

        for test_case in test_cases:
            result = self.test_single_scenario(test_case["payload"])
            results[test_case["name"]] = result

            if "avg_response_time" in result:
                overall_times.append(result["avg_response_time"])

        # ç·åˆè©•ä¾¡
        if overall_times:
            overall_avg = statistics.mean(overall_times)
            overall_grade = self._grade_performance(overall_avg, max(overall_times))
        else:
            overall_avg = 0
            overall_grade = {"grade": "F", "status": "æ¸¬å®šä¸èƒ½", "emoji": "ğŸ’¥"}

        summary = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "overall_avg_time": overall_avg,
            "overall_grade": overall_grade,
            "test_results": results,
            "recommendation": self._generate_quick_recommendation(results)
        }

        return summary

    def _generate_quick_recommendation(self, results: Dict[str, Any]) -> str:
        """ã‚¯ã‚¤ãƒƒã‚¯æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        avg_times = []
        for test_name, result in results.items():
            if "avg_response_time" in result:
                avg_times.append(result["avg_response_time"])

        if not avg_times:
            return "âŒ ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ - ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„"

        max_time = max(avg_times)
        avg_time = statistics.mean(avg_times)

        if max_time > 5.0:
            return "ğŸ”§ ç·Šæ€¥: 5ç§’è¶…é - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–ã¾ãŸã¯ã‚¯ã‚¨ãƒªãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°å¿…é ˆ"
        elif max_time > 3.0:
            return "ğŸ“ˆ æ”¹å–„æ¨å¥¨: 3ç§’è¶…é - SQLã‚¯ã‚¨ãƒªã®æœ€é©åŒ–ã‚’æ¤œè¨"
        elif avg_time < 1.0:
            return "ğŸš€ å„ªç§€ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ - ç¾çŠ¶ç¶­æŒã§å•é¡Œãªã—"
        elif avg_time < 2.0:
            return "âœ… è‰¯å¥½ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ - è»½å¾®ãªæœ€é©åŒ–ã§æ›´ãªã‚‹å‘ä¸Šå¯èƒ½"
        else:
            return "âš¡ æ¨™æº–çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ - ç¶™ç¶šçš„ãªç›£è¦–æ¨å¥¨"

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    checker = QuickPerformanceCheck()

    try:
        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        health_response = requests.get(f"{checker.api_base_url}/api/health", timeout=5)
        health_response.raise_for_status()
        print("âœ… APIã‚µãƒ¼ãƒãƒ¼æ¥ç¶šç¢ºèªå®Œäº†")

    except Exception as e:
        print(f"âŒ APIã‚µãƒ¼ãƒãƒ¼æ¥ç¶šå¤±æ•—: {e}")
        print("ğŸ’¡ è§£æ±ºæ–¹æ³•: uvicorn app.main:app --host 0.0.0.0 --port 8432")
        return

    # ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    results = checker.run_quick_benchmark()

    # çµæœè¡¨ç¤º
    print("\n" + "=" * 60)
    print("ğŸ“Š ã‚¯ã‚¤ãƒƒã‚¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ")
    print("=" * 60)

    overall_grade = results["overall_grade"]
    print(f"ğŸ† ç·åˆè©•ä¾¡: {overall_grade['emoji']} {overall_grade['grade']}ã‚°ãƒ¬ãƒ¼ãƒ‰ ({overall_grade['status']})")
    print(f"â±ï¸ å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {results['overall_avg_time']:.3f}ç§’")

    print(f"\nğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
    print(f"   {results['recommendation']}")

    print(f"\nğŸ“‹ è©³ç´°çµæœ:")
    for test_name, result in results["test_results"].items():
        if "performance_grade" in result:
            grade = result["performance_grade"]
            print(f"   {test_name}: {grade['emoji']} {result['avg_response_time']:.3f}ç§’ ({grade['status']})")

    # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    output_file = f"quick_check_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ è©³ç´°çµæœ: {output_file}")
    print("\nğŸ”„ å®šæœŸå®Ÿè¡Œæ¨å¥¨: æ©Ÿèƒ½å¤‰æ›´å¾Œã€æ¯æ—¥å®šæ™‚ã€ãƒ‡ãƒ—ãƒ­ã‚¤å‰")

if __name__ == "__main__":
    main()