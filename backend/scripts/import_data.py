"""å®Ÿãƒ‡ãƒ¼ã‚¿çµ±åˆã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆNow + VR + TPRï¼‰"""
import asyncio
import sys
from pathlib import Path
import pandas as pd
from decimal import Decimal

# backend/appã¸ã®ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import select, delete, text
from app.db.connection import init_db, get_session_maker
from app.models import (
    Talent, TalentScore, TalentImage,
    TargetSegment, ImageItem, Industry, IndustryImage, BudgetRange
)


# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ¡ãƒ¼ã‚«ãƒ¼ã‚’ä¿æŒ
AsyncSessionLocal = None


async def get_async_session():
    """éåŒæœŸã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—"""
    global AsyncSessionLocal
    if AsyncSessionLocal is None:
        await init_db()
        AsyncSessionLocal = get_session_maker()
    return AsyncSessionLocal()


# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
DB_INFO_DIR = Path(__file__).parent.parent.parent / "DBæƒ…å ±"
NOW_DATA_PATH = DB_INFO_DIR / "Nowãƒ‡ãƒ¼ã‚¿_20251126.xlsx"
VR_DIRS = [
    DB_INFO_DIR / "ã€VRâ‘ ã€‘Cåˆ—ã®äººæ°—åº¦ã¨ã€Eï½Kåˆ—ã®å„ç¨®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ¡ç”¨ã™ã‚‹æƒ³å®šã§ã™",
    DB_INFO_DIR / "ã€VRâ‘¡ã€‘Cåˆ—ã®äººæ°—åº¦ã¨ã€Eï½Kåˆ—ã®å„ç¨®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ¡ç”¨ã™ã‚‹æƒ³å®šã§ã™",
    DB_INFO_DIR / "ã€VRâ‘¢ã€‘Cåˆ—ã®äººæ°—åº¦ã¨ã€Eï½Kåˆ—ã®å„ç¨®ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’æ¡ç”¨ã™ã‚‹æƒ³å®šã§ã™",
]
TPR_DIR = DB_INFO_DIR / "ã€TPRã€‘Gåˆ—ã®ãƒ‘ãƒ¯ãƒ¼ã‚¹ã‚³ã‚¢ã‚’æ¡ç”¨ã™ã‚‹æƒ³å®šã§ã™"


# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆCSVãƒ•ã‚¡ã‚¤ãƒ«å â†’ target_segment_idï¼‰
TARGET_SEGMENT_MAPPING = {
    "ç”·æ€§12ï½19": 1,
    "å¥³æ€§12ï½19": 2,
    "ç”·æ€§20ï½34": 3,
    "å¥³æ€§20ï½34": 4,
    "ç”·æ€§35ï½49": 5,
    "å¥³æ€§35ï½49": 6,
    "ç”·æ€§50ï½69": 7,
    "å¥³æ€§50ï½69": 8,
}

# ã‚¤ãƒ¡ãƒ¼ã‚¸é …ç›®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆVRåˆ—å â†’ image_item_codeï¼‰
# VRãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿéš›ã®åˆ—åã«åˆã‚ã›ã¦ä¿®æ­£
IMAGE_ITEM_MAPPING = {
    "ãŠã‚‚ã—ã‚ã„": "funny",
    "æ¸…æ½”æ„ŸãŒã‚ã‚‹": "clean",
    "å€‹æ€§çš„ãª": "unique",  # VRãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Œå€‹æ€§çš„ãªã€
    "ä¿¡é ¼ã§ãã‚‹": "trustworthy",
    "ã‹ã‚ã„ã„": "cute",
    "ã‚«ãƒƒã‚³ã„ã„": "cool",  # VRãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Œã‚«ãƒƒã‚³ã„ã„ã€
    "å¤§äººã®é­…åŠ›ãŒã‚ã‚‹": "mature",  # VRãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Œå¤§äººã®é­…åŠ›ãŒã‚ã‚‹ã€
}


async def init_master_data():
    """ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿åˆæœŸåŒ–"""
    print("\nğŸ“Š Initializing master data...")

    async with await get_async_session() as session:
        # TRUNCATE CASCADEã§é«˜é€Ÿå‰Šé™¤
        await session.execute(text("TRUNCATE TABLE talent_images, talent_scores, talents, industry_images, industries, target_segments, image_items, budget_ranges RESTART IDENTITY CASCADE"))
        await session.commit()
        print("âœ… All tables truncated")

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ãƒã‚¹ã‚¿
        target_segments = [
            TargetSegment(id=1, code="M1", name="ç”·æ€§12-19æ­³", gender="ç”·æ€§", age_range="12-19", display_order=1),
            TargetSegment(id=2, code="F1", name="å¥³æ€§12-19æ­³", gender="å¥³æ€§", age_range="12-19", display_order=2),
            TargetSegment(id=3, code="M2", name="ç”·æ€§20-34æ­³", gender="ç”·æ€§", age_range="20-34", display_order=3),
            TargetSegment(id=4, code="F2", name="å¥³æ€§20-34æ­³", gender="å¥³æ€§", age_range="20-34", display_order=4),
            TargetSegment(id=5, code="M3", name="ç”·æ€§35-49æ­³", gender="ç”·æ€§", age_range="35-49", display_order=5),
            TargetSegment(id=6, code="F3", name="å¥³æ€§35-49æ­³", gender="å¥³æ€§", age_range="35-49", display_order=6),
            TargetSegment(id=7, code="M4", name="ç”·æ€§50-69æ­³", gender="ç”·æ€§", age_range="50-69", display_order=7),
            TargetSegment(id=8, code="F4", name="å¥³æ€§50-69æ­³", gender="å¥³æ€§", age_range="50-69", display_order=8),
        ]

        session.add_all(target_segments)
        await session.commit()
        print(f"âœ… Target segments: {len(target_segments)} records")

        # ã‚¤ãƒ¡ãƒ¼ã‚¸é …ç›®ãƒã‚¹ã‚¿
        image_items = [
            ImageItem(id=1, code="funny", name="ãŠã‚‚ã—ã‚ã„", display_order=1),
            ImageItem(id=2, code="clean", name="æ¸…æ½”æ„ŸãŒã‚ã‚‹", display_order=2),
            ImageItem(id=3, code="unique", name="å€‹æ€§çš„", display_order=3),
            ImageItem(id=4, code="trustworthy", name="ä¿¡é ¼ã§ãã‚‹", display_order=4),
            ImageItem(id=5, code="cute", name="ã‹ã‚ã„ã„", display_order=5),
            ImageItem(id=6, code="cool", name="ã‹ã£ã“ã„ã„", display_order=6),
            ImageItem(id=7, code="mature", name="è½ã¡ç€ããŒã‚ã‚‹", display_order=7),
        ]

        session.add_all(image_items)
        await session.commit()
        print(f"âœ… Image items: {len(image_items)} records")

        # äºˆç®—åŒºåˆ†ãƒã‚¹ã‚¿
        budget_ranges = [
            BudgetRange(id=1, name="1,000ä¸‡å††æœªæº€", min_amount=0, max_amount=10000000, display_order=1),
            BudgetRange(id=2, name="1,000ä¸‡å††ï½3,000ä¸‡å††æœªæº€", min_amount=10000000, max_amount=30000000, display_order=2),
            BudgetRange(id=3, name="3,000ä¸‡å††ï½5,000ä¸‡å††æœªæº€", min_amount=30000000, max_amount=50000000, display_order=3),
            BudgetRange(id=4, name="5,000ä¸‡å††ä»¥ä¸Š", min_amount=50000000, max_amount=None, display_order=4),
        ]

        session.add_all(budget_ranges)
        await session.commit()
        print(f"âœ… Budget ranges: {len(budget_ranges)} records")

        # æ¥­ç¨®ãƒã‚¹ã‚¿ï¼ˆã‚µãƒ³ãƒ—ãƒ«20ä»¶ï¼‰
        industries_data = [
            "åŒ–ç²§å“ãƒ»ãƒ˜ã‚¢ã‚±ã‚¢ãƒ»ã‚ªãƒ¼ãƒ©ãƒ«ã‚±ã‚¢", "åŒ»è–¬å“ãƒ»åŒ»ç™‚æ©Ÿå™¨", "é£Ÿå“", "é£²æ–™",
            "ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«é£²æ–™", "è‡ªå‹•è»Š", "å®¶é›»", "ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ãƒ»ã‚¢ãƒ‘ãƒ¬ãƒ«",
            "é‡‘èãƒ»ä¿é™º", "ä¸å‹•ç”£", "æ—…è¡Œãƒ»ãƒ¬ã‚¸ãƒ£ãƒ¼", "ITãƒ»é€šä¿¡",
            "æ•™è‚²ãƒ»å­¦ç¿’", "æµé€šãƒ»å°å£²", "ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ¡ãƒ³ãƒˆ", "ã‚¹ãƒãƒ¼ãƒ„",
            "ç¾å®¹ãƒ»ã‚¨ã‚¹ãƒ†", "å®¶å…·ãƒ»ã‚¤ãƒ³ãƒ†ãƒªã‚¢", "æ—¥ç”¨å“ãƒ»é›‘è²¨", "ãã®ä»–"
        ]
        industries = [Industry(name=name, display_order=idx+1) for idx, name in enumerate(industries_data)]

        session.add_all(industries)
        await session.commit()
        print(f"âœ… Industries: {len(industries)} records")


async def import_now_data():
    """Nowãƒ‡ãƒ¼ã‚¿Excelã‹ã‚‰ã‚¿ãƒ¬ãƒ³ãƒˆåŸºæœ¬æƒ…å ±ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    print("\nğŸ“¥ Importing Now data (Excel)...")

    # Excelãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    df = pd.read_excel(NOW_DATA_PATH, sheet_name=0, header=None)

    # ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œå‡ºï¼ˆæœ€åˆã®æ•°è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
    header_row = None
    for i in range(30):  # æ¤œç´¢ç¯„å›²ã‚’æ‹¡å¤§
        cell_value = str(df.iloc[i, 0]).lower()
        if "account" in cell_value or "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ" in cell_value:
            header_row = i
            break

    if header_row is None:
        print(f"âš ï¸  First 30 rows:")
        for i in range(min(30, len(df))):
            print(f"Row {i}: {df.iloc[i, 0]}")
        raise ValueError("Header row not found in Excel file")

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
    df.columns = df.iloc[header_row]
    df = df.iloc[header_row + 1:].reset_index(drop=True)

    # Excelã®ã‚«ãƒ©ãƒ æ§‹é€ ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
    # å§“åã‚’çµåˆã—ã¦nameã‚«ãƒ©ãƒ ã‚’ä½œæˆ
    df["name"] = df["last_name"].fillna("") + df["first_name"].fillna("")
    df["kana"] = df["last_name_kana"].fillna("") + df["first_name_kana"].fillna("")

    # gender_type_cd (1=ç”·æ€§, 2=å¥³æ€§)
    df["gender"] = df["gender_type_cd"].map({1: "ç”·æ€§", 2: "å¥³æ€§"})

    # birthdayã‹ã‚‰ç”Ÿå¹´ã‚’æŠ½å‡º
    df["birthday"] = pd.to_datetime(df["birthday"], errors="coerce")
    df["birth_year"] = df["birthday"].dt.year

    # act_genreã‚’categoryã«
    df["category"] = df["act_genre"]

    # money_max_one_yearãŒãªã„å ´åˆã¯Noneã«è¨­å®šï¼ˆå¾Œã§åˆ¥é€”è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼‰
    if "money_max_one_year" not in df.columns:
        df["money_max_one_year"] = None

    df_clean = df[["account_id", "name", "kana", "gender", "birth_year", "category", "money_max_one_year"]].copy()

    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
    df_clean = df_clean.dropna(subset=["account_id", "name"])
    df_clean["account_id"] = df_clean["account_id"].astype(int)
    df_clean["birth_year"] = pd.to_numeric(df_clean["birth_year"], errors="coerce")
    df_clean["money_max_one_year"] = pd.to_numeric(df_clean["money_max_one_year"], errors="coerce")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æŒ¿å…¥
    async with await get_async_session() as session:

        talents = []
        for _, row in df_clean.iterrows():
            talent = Talent(
                account_id=int(row["account_id"]),
                name=str(row["name"]),
                kana=str(row["kana"]) if pd.notna(row["kana"]) else None,
                gender=str(row["gender"]) if pd.notna(row["gender"]) else None,
                birth_year=int(row["birth_year"]) if pd.notna(row["birth_year"]) else None,
                category=str(row["category"]) if pd.notna(row["category"]) else None,
                money_max_one_year=Decimal(str(row["money_max_one_year"])) if pd.notna(row["money_max_one_year"]) else None,
            )
            talents.append(talent)

        session.add_all(talents)
        await session.commit()
        print(f"âœ… Talents: {len(talents)} records imported")

    return len(talents)


async def import_vr_data():
    """VRãƒ‡ãƒ¼ã‚¿CSVã‹ã‚‰VRäººæ°—åº¦ã¨ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚³ã‚¢ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"""
    print("\nğŸ“¥ Importing VR data (16 CSV files)...")

    # 3ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å…¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    vr_files = []
    for vr_dir in VR_DIRS:
        vr_files.extend(list(vr_dir.glob("*.csv")))

    print(f"ğŸ“ Found {len(vr_files)} VR CSV files")
    total_imported = 0
    total_scores_created = 0
    total_images_created = 0
    failed_files = []

    async with await get_async_session() as session:
        # ã‚¿ãƒ¬ãƒ³ãƒˆID ãƒãƒƒãƒ”ãƒ³ã‚°å–å¾—
        result = await session.execute(select(Talent.id, Talent.account_id, Talent.name))
        talent_map = {row.name: row for row in result.all()}
        print(f"ğŸ“Š Talent map: {len(talent_map)} talents available")

        # ã‚¤ãƒ¡ãƒ¼ã‚¸é …ç›®ID ãƒãƒƒãƒ”ãƒ³ã‚°å–å¾—
        result = await session.execute(select(ImageItem.id, ImageItem.name))
        image_item_map = {row.name: row.id for row in result.all()}
        print(f"ğŸ“Š Image item map: {image_item_map}")

        for vr_file in vr_files:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã‚’ç‰¹å®š
                target_segment_name = None
                for key in TARGET_SEGMENT_MAPPING.keys():
                    if key in vr_file.name:
                        target_segment_name = key
                        break

                if not target_segment_name:
                    print(f"âš ï¸  Skipping {vr_file.name}: target segment not found")
                    failed_files.append(f"{vr_file.name}: target segment not found")
                    continue

                target_segment_id = TARGET_SEGMENT_MAPPING[target_segment_name]

                # CSVèª­ã¿è¾¼ã¿ï¼ˆShift_JISã€skiprows=4ã«ä¿®æ­£ï¼‰
                df = pd.read_csv(vr_file, encoding="shift_jis", header=None, skiprows=4)

                # ãƒ˜ãƒƒãƒ€ãƒ¼æ¤œå‡º
                header_row = 0
                df.columns = df.iloc[header_row]
                df = df.iloc[header_row + 1:].reset_index(drop=True)

                # ã‚¿ãƒ¬ãƒ³ãƒˆåã¨äººæ°—åº¦ã€ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¹ã‚³ã‚¢æŠ½å‡º
                talent_col = df.columns[1]  # ã‚¿ãƒ¬ãƒ³ãƒˆå
                popularity_col = df.columns[2]  # Cåˆ—: äººæ°—åº¦
                image_cols = df.columns[4:11]  # E~Kåˆ—: ã‚¤ãƒ¡ãƒ¼ã‚¸7é …ç›®

                file_success_count = 0
                file_score_count = 0
                file_image_count = 0

                for idx, row in df.iterrows():
                    talent_name = str(row[talent_col]).strip()

                    if talent_name not in talent_map:
                        continue

                    talent_id = talent_map[talent_name].id
                    popularity = pd.to_numeric(row[popularity_col], errors="coerce")

                    # TalentScoreä½œæˆï¼ˆVRäººæ°—åº¦ã®ã¿ã€TPRã¯å¾Œã§çµ±åˆï¼‰
                    talent_score = TalentScore(
                        talent_id=talent_id,
                        target_segment_id=target_segment_id,
                        vr_popularity=Decimal(str(popularity)) if pd.notna(popularity) else None,
                        tpr_power_score=None,  # TPRãƒ‡ãƒ¼ã‚¿ã§å¾Œã§æ›´æ–°
                        base_power_score=None,
                    )
                    session.add(talent_score)
                    file_score_count += 1

                    # TalentImageä½œæˆï¼ˆ7é …ç›®ï¼‰
                    for img_col in image_cols:
                        vr_col_name = str(img_col).strip()
                        if vr_col_name not in IMAGE_ITEM_MAPPING:
                            continue

                        # VRåˆ—åã‹ã‚‰codeã‚’å–å¾—
                        img_code = IMAGE_ITEM_MAPPING[vr_col_name]

                        # codeã‹ã‚‰ImageItem IDã‚’ç›´æ¥å–å¾—
                        # image_item_mapã®ã‚­ãƒ¼ã¯ImageItem.nameï¼ˆDBä¸Šã®åå‰ï¼‰
                        # IMAGE_ITEM_MAPPINGã¯VRåˆ—åâ†’codeã®ãƒãƒƒãƒ”ãƒ³ã‚°
                        # ImageItemãƒã‚¹ã‚¿ã®å®šç¾©: code="funny", name="ãŠã‚‚ã—ã‚ã„"
                        code_to_name = {
                            "funny": "ãŠã‚‚ã—ã‚ã„",
                            "clean": "æ¸…æ½”æ„ŸãŒã‚ã‚‹",
                            "unique": "å€‹æ€§çš„",
                            "trustworthy": "ä¿¡é ¼ã§ãã‚‹",
                            "cute": "ã‹ã‚ã„ã„",
                            "cool": "ã‹ã£ã“ã„ã„",
                            "mature": "è½ã¡ç€ããŒã‚ã‚‹",
                        }

                        img_item_name = code_to_name.get(img_code)
                        if not img_item_name or img_item_name not in image_item_map:
                            continue

                        img_score = pd.to_numeric(row[img_col], errors="coerce")
                        if pd.notna(img_score):
                            talent_image = TalentImage(
                                talent_id=talent_id,
                                target_segment_id=target_segment_id,
                                image_item_id=image_item_map[img_item_name],
                                score=Decimal(str(img_score)),
                            )
                            session.add(talent_image)
                            file_image_count += 1

                    file_success_count += 1

                total_imported += file_success_count
                total_scores_created += file_score_count
                total_images_created += file_image_count
                print(f"âœ… {vr_file.name}: {file_success_count} talents, {file_score_count} scores, {file_image_count} images")

            except Exception as e:
                print(f"âŒ Error processing {vr_file.name}: {e}")
                failed_files.append(f"{vr_file.name}: {e}")
                continue

        await session.commit()
        print(f"\nâœ… VR data import completed:")
        print(f"   - Files processed: {len(vr_files) - len(failed_files)}/{len(vr_files)}")
        print(f"   - Talent records: {total_imported}")
        print(f"   - TalentScore records: {total_scores_created}")
        print(f"   - TalentImage records: {total_images_created}")

        if failed_files:
            print(f"\nâš ï¸  Failed files ({len(failed_files)}):")
            for failed in failed_files:
                print(f"   - {failed}")

    return total_imported


async def import_tpr_data():
    """TPRãƒ‡ãƒ¼ã‚¿CSVã‹ã‚‰TPRãƒ‘ãƒ¯ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæ—¢å­˜TalentScoreã«çµ±åˆï¼‰"""
    print("\nğŸ“¥ Importing TPR data (8 CSV files)...")

    tpr_files = list(TPR_DIR.glob("*.csv"))
    total_updated = 0

    async with await get_async_session() as session:
        # ã‚¿ãƒ¬ãƒ³ãƒˆID ãƒãƒƒãƒ”ãƒ³ã‚°å–å¾—
        result = await session.execute(select(Talent.id, Talent.account_id, Talent.name))
        talent_map = {row.name: row for row in result.all()}

        for tpr_file in tpr_files:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã‚’ç‰¹å®šï¼ˆ10-19 â†’ 12-19ã«å¤‰æ›ï¼‰
            target_segment_name = None
            file_name = tpr_file.name

            # TPRãƒ•ã‚¡ã‚¤ãƒ«åãƒ‘ã‚¿ãƒ¼ãƒ³: TPR_ç”·æ€§10ï½19_202508.csv
            if "ç”·æ€§10ï½19" in file_name:
                target_segment_name = "ç”·æ€§12ï½19"
            elif "å¥³æ€§10ï½19" in file_name:
                target_segment_name = "å¥³æ€§12ï½19"
            else:
                for key in ["ç”·æ€§20ï½34", "å¥³æ€§20ï½34", "ç”·æ€§35ï½49", "å¥³æ€§35ï½49", "ç”·æ€§50ï½69", "å¥³æ€§50ï½69"]:
                    if key in file_name:
                        target_segment_name = key
                        break

            if not target_segment_name:
                print(f"âš ï¸  Skipping {tpr_file.name}: target segment not found")
                continue

            target_segment_id = TARGET_SEGMENT_MAPPING[target_segment_name]

            # CSVèª­ã¿è¾¼ã¿ï¼ˆUTF-8 BOMä»˜ãï¼‰
            df = pd.read_csv(tpr_file, encoding="utf-8-sig")

            # ã‚¿ãƒ¬ãƒ³ãƒˆåã¨ãƒ‘ãƒ¯ãƒ¼ã‚¹ã‚³ã‚¢æŠ½å‡ºï¼ˆGåˆ—ï¼‰
            if "ã‚¿ãƒ¬ãƒ³ãƒˆå" not in df.columns or "ã‚¹ã‚³ã‚¢" not in df.columns:
                print(f"âš ï¸  Skipping {tpr_file.name}: required columns not found")
                continue

            for _, row in df.iterrows():
                talent_name = str(row["ã‚¿ãƒ¬ãƒ³ãƒˆå"]).strip()

                if talent_name not in talent_map:
                    continue

                talent_id = talent_map[talent_name].id
                power_score = pd.to_numeric(row["ã‚¹ã‚³ã‚¢"], errors="coerce")

                if pd.notna(power_score):
                    # æ—¢å­˜TalentScoreã‚’æ›´æ–°
                    result = await session.execute(
                        select(TalentScore)
                        .filter_by(talent_id=talent_id, target_segment_id=target_segment_id)
                    )
                    talent_score = result.scalar_one_or_none()

                    if talent_score:
                        talent_score.tpr_power_score = Decimal(str(power_score))
                        # åŸºç¤ãƒ‘ãƒ¯ãƒ¼å¾—ç‚¹è¨ˆç®—ï¼ˆSTEP1ï¼‰
                        if talent_score.vr_popularity:
                            talent_score.base_power_score = (
                                talent_score.vr_popularity + Decimal(str(power_score))
                            ) / 2
                    else:
                        # VRãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯æ–°è¦ä½œæˆ
                        talent_score = TalentScore(
                            talent_id=talent_id,
                            target_segment_id=target_segment_id,
                            vr_popularity=None,
                            tpr_power_score=Decimal(str(power_score)),
                            base_power_score=None,
                        )
                        session.add(talent_score)

                    total_updated += 1

        await session.commit()
        print(f"âœ… TPR data: {total_updated} talent scores updated (8 CSV files)")

    return total_updated


async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸš€ Starting data import process...")
    print("=" * 60)

    try:
        # ãƒã‚¹ã‚¿ãƒ‡ãƒ¼ã‚¿åˆæœŸåŒ–
        await init_master_data()

        # Nowãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        now_count = await import_now_data()

        # VRãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        vr_count = await import_vr_data()

        # TPRãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        tpr_count = await import_tpr_data()

        print("\n" + "=" * 60)
        print("âœ… Data import completed successfully!")
        print("=" * 60)
        print(f"ğŸ“Š Summary:")
        print(f"   - Talents: {now_count} records")
        print(f"   - VR data: {vr_count} talent records (16 files)")
        print(f"   - TPR data: {tpr_count} talent scores (8 files)")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ Error during import: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
